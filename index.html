<!DOCTYPE html>

<html>
<head>
<meta charset="utf-8"/>
<title>Ge Li</title>
<link href="css/homepage.css" rel="stylesheet" type="text/css"/>
<meta content="width=device-width, initial-scale=1.0" name="viewport"/>
<link href="css/login.css" rel="stylesheet"/> <!-- 引入CSS文件 -->
<script src="js/login.js"></script> <!-- 引入JavaScript文件 -->
</head>
<style></style>
<body>
<div class="topmenu">
<ul class="ul_nav">
<li class="li_nav"><a class="li_nav_a" href="#Home">Home</a></li>
<li><a class="li_nav_a" href="index.html#Publications">Publications</a></li>
<li><a class="li_nav_a" href="teaching.html#Teaching">Teaching</a></li>
<li><a class="li_nav_a" href="services.html#Services">Services</a></li>
<li><a class="li_nav_a" href="#" onclick="showLoginPopup('ongoing.html'); return false;">Researching</a>
</li>
<li><a class="li_nav_a" href="#" onclick="showLoginPopup('readingList.html'); return false;">Guided_Reading</a></li>
</ul>
</div>
<div class="namecard" id="Home">
<div class="mypic"></div>
<div class="contact">
<div class="name">Ge Li</div>
<div class="title">Full Professor with Tenure</div>
<div class="myinfo">
<p>School of Computer Science</p>
<p>Peking University</p>
<p>lige@pku.edu.cn</p>
</div>
<div class="logos">
<div class="pku_logo"></div>
<div class="aiXcoder_logo"></div>
</div>
</div>
</div>
<div class="contentframe">
<div class="content">
<h2 id="Publications">About</h2>
<ul class="paperlist">
<p>I am now a full professor with tenure in the School of Computer Science in Peking University. I
                    obtained my Ph.D. from Peking University in 2006. I had been a visiting associate professor at
                    Artificial Intelligence Laboratory of Stanford University in 2013-2014. My current research mainly
                    concerns applications of probabilistic methods for machine learning, including Program Language
                    Processing, Natural Language Processing, and Software Engineering.</p>
</ul>
<h2>Preprints</h2>
<ul class="paperlist">
<li class="paper"><b class="paperinf">[arXiv 2025]</b> Kechi Zhang, <b class="myname">Ge Li</b>, Jia Li, Huangzhao Zhang, Jingjing Xu, Hao Zhu, Lecheng Wang, Yihong Dong, Jing Mai, Bin Gu, Zhi Jin; Computational Thinking Reasoning in Large Language Models; arXiv preprint, <a href="https://arxiv.org/abs/2506.02658" target="_blank">arXiv: 2506.02658</a>, 2025.</li>
<li class="paper"><b class="paperinf">[arXiv 2025]</b> Huanyu Liu, Jia Li, Hao Zhu, Kechi Zhang, Yihong Dong, <b class="myname">Ge Li</b>; SATURN: SAT-based Reinforcement Learning to Unleash Language Model Reasoning; arXiv preprint, <a href="https://arxiv.org/abs/2505.16368" target="_blank">arXiv: 2505.16368</a>, 2025.</li>
<li class="paper"><b class="paperinf">[arXiv 2025]</b> Yuqi Zhu, <b class="myname">Ge Li</b>, Xue Jiang, Jia Li, Hong Mei, Zhi Jin, Yihong Dong; Uncertainty-Guided Chain-of-Thought for Code Generation with LLMs; arXiv preprint, <a href="https://arxiv.org/pdf/2503.15341" target="_blank">arXiv: 2503.15341</a>, 2025.<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=15218041727249303368" target="_blank"> (Cited by 3)</a></span></li>
<li class="paper"><b class="paperinf">[arXiv 2025]</b> Jia Li, Xianjie Shi, Kechi Zhang, Lei Li, <b class="myname">Ge Li</b>, Zhengwei Tao, Fang Liu, Chongyang Tao, Zhi Jin; CodeRAG: Supportive Code Retrieval on Bigraph for Real-World Code Generation; arXiv preprint, <a href="https://arxiv.org/pdf/2504.10046" target="_blank">arXiv: 2504.10046</a>, 2025.<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=14720281153510071392" target="_blank"> (Cited by 1)</a></span></li>
<li class="paper"><b class="paperinf">[arXiv 2025]</b> Jia Li, Hao Zhu, Huanyu Liu, Xianjie Shi, He Zong, Yihong Dong, Kechi Zhang, Siyuan Jiang, Zhi Jin, <b class="myname">Ge Li</b>; aiXcoder-7B-v2: Training LLMs to Fully Utilize the Long Context in Repository-level Code Completion; arXiv preprint, <a href="https://arxiv.org/abs/2503.15301" target="_blank">arXiv: 2503.15301</a>, 2025. <span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=15788931866516891147" target="_blank"> (Cited by 1)</a></span></li>
<li class="paper"><b class="paperinf">[arXiv 2025]</b> Yihong Dong, <b class="myname">Ge Li</b>, Xue Jiang, Yongding Tao, Kechi Zhang, Hao Zhu, Huanyu Liu, Jiazheng Ding, Jia Li, Jinliang Deng, Hong Mei; FANformer: Improving Large Language Models Through Effective Periodicity Modeling, arXiv preprint, <a href="https://arxiv.org/abs/2502.21309" target="_blank">arXiv: 2502.21309</a>, 2025.</li>
<li class="paper"><b class="paperinf">[arXiv 2024]</b> Lecheng Wang, Xianjie Shi, <b class="myname">Ge Li</b>, Jia Li, Yihong Dong, Xuanming Zhang, Wenpin Jiao, Hong Mei; Why Language Models Collapse When Trained on Recursively Generated Text; arXiv preprint, <a href="https://arxiv.org/abs/2412.14872" target="_blank">arXiv: 2412.14872</a>, 2024.</li>
<li class="paper"><b class="paperinf">[arXiv 2024]</b> Yihong Dong, <b class="myname">Ge Li</b>, Yongding Tao, Xue Jiang, Kechi Zhang, Jia Li, Jing Su, Jun Zhang, Jingjing Xu; FAN: Fourier Analysis Networks; arXiv preprint, <a href="https://arxiv.org/abs/2410.02675" target="_blank">arXiv: 2410.02675</a>, 2024.<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=17560245044847788695" target="_blank"> (Cited by 8)</a></span></li>
<li class="paper"><b class="paperinf">[arXiv 2024]</b> Jia Li, <b class="myname">Ge Li</b>, Lecheng Wang, Hao Zhu, Zhi Jin; Generating Equivalent Representations of Code By A Self-Reflection Approach; arXiv preprint, <a href="https://arxiv.org/abs/2410.03351" target="_blank">arXiv: 2410.03351</a>, 2024.<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=1390657844510261600" target="_blank"> (Cited by 1)</a></span></li>
<li class="paper"><b class="paperinf">[arXiv 2024]</b> Xue Jiang, Yihong Dong, Zhi Jin, <b class="myname">Ge Li</b>; SEED: Customize Large Language Models with Sample-Efficient Adaptation for Code Generation; arXiv preprint, <a href="https://arxiv.org/abs/2403.00046" target="_blank">arXiv: 2403.00046</a>, 2024.<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=15151453715030596900" target="_blank"> (Cited by 5)</a></span></li>
<li class="paper"><b class="paperinf">[arXiv 2023]</b> Zhang, Kechi, <b class="myname">Ge Li</b>, Jia Li, Zhuo Li, Zhi Jin; ToolCoder: Teach Code Generation Models to Use API Search Tool; arXiv preprint, <a href="https://arxiv.org/abs/2305.04032" target="_blank">arXiv: 2305.04032</a>, 2023.<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=8999169128688149784" target="_blank"> (Cited by 62)</a></span></li>
<li class="paper"><b class="paperinf">[arXiv 2023]</b> Zejun Wang, Jia Li, <b class="myname">Ge Li</b>, Zhi Jin; ChatCoder: Chat-based Refine Requirement Improves LLMs' Code Generation; arXiv preprint, <a href="https://arxiv.org/abs/2311.00272" target="_blank">arXiv: 2311.00272</a>, 2023.</li>
<li class="paper"><b class="paperinf">[arXiv 2022]</b> Zhang, Kechi, <b class="myname">Ge Li</b>, Zhi Jin; What Does Transformer Learn About Source Code?; arXiv preprint, <a href="https://arxiv.org/abs/2207.08466" target="_blank">arXiv: 2207.08466</a>, 2022.<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=3542087855640985564" target="_blank"> (Cited by 11)</a></span></li>
</ul>
<h2 style="display: inline;">Selected Publications</h2>
<a download="myPaperRefs.bib" href="../files/BibTex/myPaperRefs.bib" style="display: inline; margin-left: 10px;">BibTex</a>
<a download="geBibStyle.bst" href="../files/BibTex/geBibStyle.bst" style="display: inline; margin-left: 10px;">BibSytle</a>
<ul class="paperlist">
<li class="paper"><b class="paperinf">[ICSE 2026]</b> Kechi Zhang, Huangzhao Zhang, <b class="myname">Ge Li</b>, Jinliang You, Jia Li, Yunfei Zhao, Zhi Jin; SEAlign: Alignment Training for Software Engineering Agent; Proceedings of the 48th IEEE/ACM International Conference on Software Engineering (ICSE 2026), Rio de Janeiro, Brazil, Apr. 12 - 18, 2026. (Accepted) <span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=13020159365704232745" target="_blank"> (Cited by 1)</a></span></li>
<li class="paper"><b class="paperinf">[ACL 2025]</b> Kechi Zhang, <b class="myname">Ge Li</b>, Yihong Dong, Jingjing Xu, Jun Zhang, Jing Su, Yongfei Liu, Zhi Jin; CodeDPO: Aligning Code Models with Self Generated and Verified Source Code; Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (ACL 2025), Vienna, Austria, Jul. 27 - Aug. 1, 2025. (Accepted)<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=602714782809980011" target="_blank"> (Cited by 16)</a></span></li>
<li class="paper"><b class="paperinf">[ACL 2025]</b> Yihong Dong, Yuchen Liu, Xue Jiang, Zhi Jin, <b class="myname">Ge Li</b>; Rethinking Repetition Problems in Code Generation; Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (ACL 2025), Vienna, Austria, Jul. 27 - Aug. 1, 2025. (Accepted)<span class="citation-count" style="color: green; font-size:0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=9690201618174311686" target="_blank"> (Cited by 1)</a></span></li>
<li class="paper"><b class="paperinf">[ACL 2025]</b> Kechi Zhang, <b class="myname">Ge Li</b>, Jia Li, Yihong Dong, Jia Li, Zhi Jin; Focused-DPO: Enhancing Code Generation Through Focused Preference Optimization on Error-Prone Points; Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics, Vienna, Austria (ACL 2025), Jul. 27 - Aug. 1, 2025. (Accepted)<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=1997961016148982565" target="_blank"> (Cited by 5)</a></span></li>
<li class="paper"><b class="paperinf">[ACL 2025]</b> Kaibo Liu, Zhenpeng Chen, Yiyang Liu, Jie Zhang, Mark Harman, Yudong Han, Yun Ma, Yihong Dong, <b class="myname">Ge Li</b>, Gang Huang; LLM-Powered Test Case Generation for Detecting Bugs in Plausible Programs; Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics, Vienna, Austria (ACL 2025), Jul. 27 - Aug. 1, 2025. (Accepted)</li>
<li class="paper"><b class="paperinf">[ACL 2025]</b> Jia Li, Xuyuan Guo, Lei Li, Kechi Zhang, <b class="myname">Ge Li</b>, Jia Li, Zhengwei Tao, Fang Liu, Chongyang Tao, Yuqi Zhu, Zhi Jin; Benchmarking Long-Context Language Models on Long Code Understanding; Proceedings of the 63rd Annual Meeting of the Association for Computational Linguistics (ACL 2025), Vienna, Austria, Jul. 27 - Aug. 1, 2025. (Accepted)<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=12236359998315825621" target="_blank"> (Cited by 1)</a></span></li>
<li class="paper"><b class="paperinf">[ICSE 2025]</b> Siyuan Jiang, Jia Li, He Zong, Huanyu Liu, Hao Zhu, Shukai Hu, Erlu Li, Jiazheng Ding, Yu Han, Wei Ning, <b class="myname">Ge Li</b>; aiXcoder-7B: A Lightweight and Effective Large Language Model for Code Completion; Proceedings of the 47th IEEE/ACM International Conference on Software Engineering (ICSE), Ottawa, Ontario, Canada, Apr. 27 - May 3, 2025 (Accepted).<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=10988146982571642357" target="_blank"> (Cited by 7)</a></span></li>
<li class="paper"><b class="paperinf">[ICSE 2025]</b> Xue Jiang, Yihong Dong, Yongding Tao, Huanyu Liu, Zhi Jin, <b class="myname">Ge Li</b>; ROCODE: Integrating Backtracking Mechanism and Program Analysis in Large Language Models for Code Generation; Proceedings of the 47th IEEE/ACM International Conference on Software Engineering (ICSE), Ottawa, Ontario, Canada, Apr. 27 - May 3, 2025 (Accepted).<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=2207929275716257375" target="_blank"> (Cited by 4)</a></span></li>
<li class="paper"><b class="paperinf">[EMSE, 2025]</b> Kechi Zhang, Jia Li, Zhuo Li, Zhi Jin, <b class="myname">Ge Li</b>; Transformer-based Code Model with Compressed Hierarchy Representation; Empirical Software Engineering (EMSE), Vol. 30, Iss. 2, Mar. 2025, pp.1-43. [<a href="My Papers/2024 - TOSEM - Transformer-based Code Model with Compressed Hierarchy Representation.pdf" target="_blank">PDF</a>] </li>
<li class="paper"><b class="paperinf">[EMSE, 2025]</b> Jia Li, Zheng Fang, Xianjie Shi, Zhi Jin, Fang Liu, Yunfei Zhao, <b class="myname">Ge Li</b>; SCodeSearcher: Soft Contrastive Learning for Code Search; Empirical Software Engineering, Vol. 30, Iss. 3, May 2025, pp. 1-23. [<a href="My Papers/2025 - EMSE - SCodeSearcher: Soft Contrastive Learning for Code Search.pdf" target="_blank">PDF</a>]</li>
<li class="paper"><b class="paperinf">[TOSEM, 2025]</b> Yuwei Zhang, Zhi Jin, Ying Xing, <b class="myname">Ge Li</b>, Fang Liu, Jiaxin Zhu, Wensheng Dou, Jun Wei; PATCH: Empowering Large Language Model with Programmer-Intent Guidance and Collaborative-Behavior Simulation for Automatic Bug Fixing; ACM Transactions on Software Engineering and Methodology (TOSEM), 2025. [<a href="My Papers/2025 - TOSEM - PATCH- Empowering Large Language Model with Programmer-Intent Guidance and Collaborative-Behavior Simulation for Automatic Bug Fixing.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=4512200624169268396" target="_blank"> (Cited by 1)</a></span></li>
<li class="paper"><b class="paperinf">[TOSEM, 2025]</b> Jia Li, <b class="myname">Ge Li</b>, Yongmin Li, Jin Zhi; Structured Chain-of-Thought Prompting for Code Generation; ACM Transactions on Software Engineering and Methodology (TOSEM), Vol. 34, Iss. 2, Jan. 2025, pp.1-23. [<a href="My Papers/2025 - TOSEM - Structured Chain-of-Thought Prompting for Code Generation.pdf" target="_blank">PDF</a>] <span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=17573273940722685551" target="_blank"> (Cited by 153)</a></span></li>
<li class="paper"><b class="paperinf">[TOSEM, 2024]</b> Yihong Dong, Jiazheng Ding, Xue Jiang, <b class="myname">Ge Li</b>, Zhuo Li, Zhi Jin; Evaluating Code Generation by Learning Code Execution; ACM Transactions on Software Engineering and Methodology (TOSEM), Vol. 33, No. 7, Article 182, Sep. 2024. [<a href="My Papers/2024 - TOSEM - CodeScore - Evaluating Code Generation by Learning Code Execution.pdf" target="_blank">PDF</a>] <span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=15106523673243699730" target="_blank"> (Cited by 68)</a></span></li>
<li class="paper"><b class="paperinf">[ASE 2024]</b> Zejun Wang, Kaibo Liu, <b class="myname">Ge Li</b>, Zhi Jin; SlicePromptTest4J: High-coverage Test Generation using LLM via Method Slicing; Proceedings of the 39th IEEE/ACM International Conference on Automated Software Engineering (ASE 2024), Sacramento, California, United States, Oct. 27 - Nov. 1, 2024, pp.1258 - 1268. [<a href="My Papers/2024 - ASE - SlicePromptTest4J- High-coverage Test Generation using LLM via Method Slicing.pdf" target="_blank">PDF</a>]</li>
<li class="paper"><b class="paperinf">[NeurIPS 2024]</b> Jia Li, <b class="myname">Ge Li</b>, Xuanming Zhang, Yunfei Zhao, Yihong Dong, Zhi Jin, Binhua Li, Fei Huang, Yongbin Li; EvoCodeBench: An Evolving Code Generation Benchmark with Domain-Specific Evaluations; Proceedings of the 38th Annual Conference on Neural Information Processing Systems (NeurIPS 2024); Vancouver, Canada, Dec. 10-15, 2024. [<a href="My Papers/2024 - NeurIPS - EvoCodeBench- An Evolving Code Generation Benchmark with Domain-Specific Evaluations.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=5226067679174332295" target="_blank"> (Cited by 15)</a></span></li>
<li class="paper"><b class="paperinf">[TOSEM, 2024]</b> Jia Li, Yunfei Zhao, Yongmin Li, <b class="myname">Ge Li</b>, Zhi Jin; AceCoder: An Effective Prompting Technique Specialized in Code Generation; ACM Transactions on Software Engineering and Methodology (TOSEM), Vol. 33, No. 8, Article 204, Nov. 2024. [<a href="My Papers/2024 - TOSEM - AceCoder- An Effective Prompting Technique Specialized in Code Generation.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=16975702538622477751" target="_blank"> (Cited by 27)</a></span></li>
<li class="paper"><b class="paperinf">[TOSEM, 2024]</b> Yihong Dong, Xue Jiang, Zhi Jin, <b class="myname">Ge Li</b>; Self-collaboration Code Generation via ChatGPT; ACM Transactions on Software Engineering and Methodology (TOSEM), Vol. 33, No. 7, Article 189, Sep. 2024. [<a href="My Papers/2024 - TOSEM - Self-collaboration Code Generation via ChatGPT.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=14068134124059091664" target="_blank"> (Cited by 301)</a></span></li>
<li class="paper"><b class="paperinf">[TOSEM, 2024]</b> Xue Jiang, Yihong Dong, Lecheng Wang, Zheng Fang, Qiwei Shang, <b class="myname">Ge Li</b>, Zhi Jin, Wenpin Jiao; Self-Planning Code Generation with Large Language Model; ACM Transactions on Software Engineering and Methodology (TOSEM), Vol. 33, No. 7, Article 182, Sep. 2024. [<a href="My Papers/2024 - TOSEM - Self-Planning Code Generation with Large Language Model.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=4235216703937477468" target="_blank"> (Cited by 192)</a></span></li>
<li class="paper"><b class="paperinf">[JSEP, 2024]</b> Huangzhao Zhang, Zhuo Li, Zhi Jin, <b class="myname">Ge Li</b>; WELL: Applying Bug Detectors to Bug Localization via Weakly Supervised Learning; Journal of Software: Evolution and Process, Vol. 36, No. 9, Sep 01, 2024. doi: 10.1002/smr.2669. pp 1-23. [<a href="My Papers/2024 - JSEP - WELL- Applying Bug Detectors to Bug Localization via Weakly Supervised Learning.pdf" target="_blank">PDF</a>]</li>
<li class="paper"><b class="paperinf">[ACL 2024]</b> Kechi Zhang, <b class="myname">Ge Li</b>, Huangzhao Zhang, Zhi Jin; HiRoPE: Length Extrapolation for Code Models Using Hierarchical Position; Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (ACL 2024), Bangkok, Thailand, Aug. 11-16, 2024. [<a href="My Papers/2024 - ACL - HiRoPE- Length Extrapolation for Code Models Using Hierarchical Position.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=13522423733386863203" target="_blank"> (Cited by 10)</a></span></li>
<li class="paper"><b class="paperinf">[ACL 2024]</b> Kechi Zhang, Jia Li, <b class="myname">Ge Li</b>, Xianjie Shi, Zhi Jin; CodeAgent: Enhancing Code Generation with Tool-Integrated Agent Systems for Real-World Repo-level Coding Challenges; Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (ACL 2024), Bangkok, Thailand, Aug. 11-16, 2024. [<a href="My Papers/2024 - ACL - CodeAgent- Enhancing Code Generation with Tool-Integrated Agent Systems for Real-World Repo-level Coding Challenges.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=7561981007078652264" target="_blank"> (Cited by 101)</a></span></li>
<li class="paper"><b class="paperinf">[ACL 2024]</b> Yihong Dong, Xue Jiang, Huanyu Liu, Zhi Jin, <b class="myname">Ge Li</b>; Generalization or Memorization: Data Contamination and Trustworthy Evaluation for Large Language Models; Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (ACL 2024), Bangkok, Thailand, Aug. 11-16, 2024. [<a href="My Papers/2024 - ACL - Generalization or Memorization- Data Contamination and Trustworthy Evaluation for Large Language Models.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=12772159853626181897" target="_blank"> (Cited by 92)</a></span></li>
<li class="paper"><b class="paperinf">[ACL 2024]</b> Jia Li, <b class="myname">Ge Li</b>, Yunfei Zhao, Yongmin Li, Zhi Jin, Hao Zhu, Huanyu Liu, Kaibo Liu, Lecheng Wang, Zheng Fang, Lanshen Wang, Jiazheng Ding, Xuanming Zhang, Yihong Dong, Yuqi Zhu; DevEval: A Manually-Annotated Code Generation Benchmark Aligned with Real-World Code Repositories; Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (ACL 2024), Bangkok, Thailand, Aug. 11-16, 2024. [<a href="My Papers/2024 - ACL - DevEval- A Manually-Annotated Code Generation Benchmark Aligned with Real-World Code Repositories.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=6955735688539690598" target="_blank"> (Cited by 27)</a></span></li>
<li class="paper"><b class="paperinf">[ACL 2024]</b> Yihong Dong, Kangcheng Luo, Xue Jiang, Zhi Jin, <b class="myname">Ge Li</b>; PACE: Improving Prompt with Actor-Critic Editing for Large Language Model; Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (ACL 2024), Bangkok, Thailand, Aug. 11-16, 2024. [<a href="My Papers/2024 - ACL - PACE- Improving Prompt with Actor-Critic Editing for Large Language Model.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=12415913045874939699" target="_blank"> (Cited by 16)</a></span></li>
<li class="paper"><b class="paperinf">[FSE 2024]</b> Bolun Li, Zhihong Sun, Tao Huang, Hongyu Zhang, Yao Wan, <b class="myname">Ge Li</b>, Zhi Jin, Chen Lyu; IRCoCo: Immediate Rewards-Guided Deep Reinforcement Learning for Code Completion; Proceedings of the 2024 ACM International Conference on the Foundations of Software Engineering (FSE), Porto de Galinhas, Brazil, July 15-19, 2024. [<a href="My Papers/2024 - FSE - IRCoCo- Immediate Rewards-Guided Deep Reinforcement Learning for Code Completion.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=5031481856160712951" target="_blank"> (Cited by 11)</a></span></li>
<li class="paper"><b class="paperinf">[FSE 2024]</b> Zhen Yang, Fang Liu, Zhongxing Yu, Jacy Wai Keung, Jia Li, Shuo Liu, Yifan Hong, Xiaoxue Ma, Zhi Jin, <b class="myname">Ge Li</b>; Exploring and Unleashing the Power of Large Language Models in Automated Code Translation; Proceedings of the 2024 ACM International Conference on the Foundations of Software Engineering (FSE), Porto de Galinhas, Brazil, July 15-19, 2024. [<a href="My Papers/2024 - FSE - Exploring and Unleashing the Power of Large Language Models in Automated Code Translation.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=13351935780858102292" target="_blank"> (Cited by 81)</a></span></li>
<li class="paper"><b class="paperinf">[TSE, 2024]</b> Xin-Cheng Wen, Cuiyun Gao, Feng Luo, Haoyu Wang, <b class="myname">Ge Li</b>, and Qing Liao; LIVABLE: Exploring Long-Tailed Classification of Software Vulnerability Types; IEEE Transactions on Software Engineering (TSE), Vol. 50, Iss. 6, Jun. 2024, pp. 1325-1339. [<a href="My Papers/2024 - TOSEM - LIVABLE- Exploring Long-Tailed Classification of Software Vulnerability Types.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=614923270475268161" target="_blank"> (Cited by 15)</a></span></li>
<li class="paper"><b class="paperinf">[LREC-COLING 2024]</b> Zhihong Sun, Chen Lyu, Yao Wan, Hongyu Zhang, <b class="myname">Ge Li</b>, Zhi Jin; Enhancing Code Generation Performance of Smaller Models by Distilling the Reasoning Ability of LLMs; Proceedings of the 2024 Joint International Conference on Computational Linguistics, Language Resources and Evaluation (LREC-COLING), Torino, Italia, May 20-25, 2024. [<a href="My Papers/2024 - LREC-COLING - Enhancing Code Generation Performance of Smaller Models by Distilling the Reasoning Ability of LLMs.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=675215571974267747" target="_blank"> (Cited by 17)</a></span></li>
<li class="paper"><b class="paperinf">[ICPC 2024]</b> Tao Huang, Zhihong Sun, Zhi Jin, <b class="myname">Ge Li</b>, Chen Lyu; Knowledge-Aware Code Generation with Large Language Models; Proceedings of the 32nd ACM/IEEE International Conference on Program Comprehension (ICPC), Lisbon, Portugal, April 15-16, 2024. [<a href="My Papers/2024 - ICPC - Knowledge-Aware Code Generation with Large Language Models.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=359324140428855047" target="_blank"> (Cited by 16)</a></span></li>
<li class="paper"><b class="paperinf">[ICSE 2024]</b> Tao Huang, Zhihong Sun, Zhi Jin, <b class="myname">Ge Li</b>, Chen Lyu; KareCoder: A New Knowledge-Enriched Code Generation System; Proceedings of the 46th ACM/IEEE International Conference on Software Engineering (ICSE), Lisbon, Portugal, April 14-20, 2024.(Short) [<a href="My Papers/2024 - ICSE - Short - KareCoder- A New Knowledge-Enriched Code Generation System.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=13748585383696919377" target="_blank"> (Cited by 4)</a></span></li>
<li class="paper"><b class="paperinf">[JSEP, 2024]</b> Huangzhao Zhang, Shuai Lu, Zhuo Li, Zhi Jin, Lei Ma, Yang Liu, <b class="myname">Ge Li</b>; Codebert-Attack: Adversarial Attack against Source Code Deep Learning Models via Pre-trained Model; Journal of Software: Evolution and Process, Vol. 36, Iss. 3, Mar., 2024 [<a href="My Papers/2024 - JSEP - Codebert-Attack- Adversarial Attack against Source Code Deep Learning Models via Pre-trained Model.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=17242215769330747796" target="_blank"> (Cited by 12)</a></span></li>
<li class="paper"><b class="paperinf">[SCIS, 2024]</b> Huangzhao Zhang, Kechi Zhang, Zhuo Li, Jia Li, Jia Li, Yongmin Li, Yunfei Zhao, Yuqi Zhu, Fang Liu, <b class="myname">Ge Li</b>, Zhi Jin; Deep Learning for Code Generation: A Survey; Science China Information Sciences (SCIS), doi: 10.1007/s11432-023-3956-3, Feb 6, 2024. [<a href="My Papers/2024 - SCIS - Deep Learning for Code Generation - A Survey.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=9964711056121178532" target="_blank"> (Cited by 9)</a></span></li>
<li class="paper"><b class="paperinf">[TOSEM, 2024]</b> Jia Li, Zhuo Li, Huangzhao Zhang, <b class="myname">Ge Li</b>, Zhi Jin, Xing Hu, Xin Xia; Poison Attack and Poison Detection on Deep Source Code Processing Models; ACM Transactions on Software Engineering and Methodology (TOSEM), Vol. 33, No. 62, Mar. 14, 2024, pp 1-31. [<a href="My Papers/2024 - TOSEM - Poison Attack and Poison Detection on Deep Source Code Processing Models.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=12660933787426516615" target="_blank"> (Cited by 28)</a></span></li>
<li class="paper"><b class="paperinf">[AAAI 2024]</b> Yuqi Zhu, <a href="https://lj2lijia.github.io/index.html">Jia Allen Li</a>, <b class="myname">Ge Li</b>, YunFei Zhao, Jia Li, Zhi Jin, Hong Mei; Hot or Cold? Adaptive Temperature Sampling for Code Generation with Large Language Models; Proceedings of the 38th Annual AAAI Conference on Artificial Intelligence (AAAI), Vancouver, Canada, Feb 20-27, 2024. [<a href="My Papers/2024 - AAAI - Hot or Cold - Adaptive Temperature Sampling for Code Generation with Large Language Models.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=15449504382001947561" target="_blank"> (Cited by 43)</a></span></li>
<li class="paper"><b class="paperinf">[ASEJ, 2023]</b> Zejun Wang, Fang Liu, Yiyang Hao, Zhi Jin; AdaComplete: improve DL-based code completion method’s domain adaptability; Automated Software Engineering (ASEJ), Vol. 30, No. 1, Mar 06, 2023, pp 28-39. [<a href="My Papers/2023 - ASEJ - AdaComplete- Improve DL-based Code Completion Method’s Domain Adaptability.pdf" target="_blank">PDF</a>] </li>
<li class="paper"><b class="paperinf">[Internetware 2023]</b> Jia Li, Fang Liu, Jia Allen Li, Yunfei Zhao, <b class="myname">Ge Li</b>, and Zhi Jin; Mcodesearcher: Multi-view Contrastive Learning for Code Search; Proceedings of the 14th Asia-Pacific Symposium on Internetware (Internetware), Hangzhou, China, August 4-6, 2023. [<a href="My Papers/2023 - Internetware - Mcodesearcher- Multi-view Contrastive Learning for Code Search.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=3548263619858824067" target="_blank"> (Cited by 4)</a></span></li>
<li class="paper"><b class="paperinf">[Internetware 2023]</b> Yunfei Zhao, Yihong Dong, <b class="myname">Ge Li</b>; Seq2Seq or Seq2Tree: Generating Code Using Both Paradigms via Mutual Learning; Proceedings of the 14th Asia-Pacific Symposium on Internetware (Internetware), Hangzhou, China, August 4-6, 2023, pp 238 - 248. [<a href="My Papers/2023 - Internetware - Seq2Seq or Seq2Tree- Generating Code Using Both Paradigms via Mutual Learning.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=10480058470957227065" target="_blank"> (Cited by 4)</a></span></li>
<li class="paper"><b class="paperinf">[ECAI 2023]</b> Yihong Dong, <b class="myname">Ge Li</b>, Xue Jiang, Zhi Jin; Antecedent Predictions Are More Important Than You Think: An Effective Method for Tree-Based Code Generation; Proceedings of the 26th European Conference on Artificial Intelligence (ECAI), Kraków, Poland, Sept. 30 - Oct. 4, 2023. pp 565-574. [<a href="My Papers/2023 - ECAI - Antecedent Predictions Are More Important Than You Think - An Effective Method for Tree-Based Code Generation.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=16158950144771320146" target="_blank"> (Cited by 2)</a></span></li>
<li class="paper"><b class="paperinf">[ASE 2023]</b> Jia Li, Chongyang Tao, Zhi Jin, Fang Liu, <a href="https://lj2lijia.github.io/index.html">Jia Allen Li</a>, <b class="myname">Ge Li</b>; ZC3 Zero-Shot Cross-Language Code Clone Detection; Proceedings of the 38th IEEE/ACM International Conference on Automated Software Engineering (ASE), Kirchberg, Luxembourg, September 11-15, 2023. [<a href="My Papers/2023 - ASE - ZC3 Zero-Shot Cross-Language Code Clone Detection.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=3193022310429670081" target="_blank"> (Cited by 11)</a></span></li>
<li class="paper"><b class="paperinf">[ACL 2023]</b> Kechi Zhang, Zhuo Li, <a href="https://lj2lijia.github.io/index.html">Jia Allen Li</a>, <b class="myname">Ge Li</b>, Zhi Jin; Self-Edit: Fault-Aware Code Editor for Code Generation; Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (ACL), Toronto, Canada, July 9-14, 2023. [<a href="My Papers/2023 - ACL - Self-Edit- Fault-Aware Code Editor for Code Generation.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=4487781111471187233" target="_blank"> (Cited by 136)</a></span></li>
<li class="paper"><b class="paperinf">[TOSEM, 2023]</b> <a href="https://lj2lijia.github.io/index.html">Jia Allen Li</a>, <b class="myname">Ge Li</b>, Zhuo Li, Zhi Jin, Xing Hu, Kechi Zhang, Zhiyi Fu; CodeEditor: Learning to Edit Source Code with Pre-trained Models; ACM Transactions on Software Engineering and Methodology (TOSEM), Vol. 32, No. 6, May 22, 2023, pp 143-165. [<a href="My Papers/2023 - TOSEM - CodeEditor- Learning to Edit Source Code with Pre-trained Models.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=11510210383782264150" target="_blank"> (Cited by 41)</a></span></li>
<li class="paper"><b class="paperinf">[ISSTA 2023]</b> Yihong Dong, <b class="myname">Ge Li</b>, Jiazheng Ding, Zhi Jin; CODEP: Grammatical Seq2Seq Model for General-Purpose Code Generation; Proceedings of the ACM Sigsoft International Symposium on Software Testing and Analysis (ISSTA'23), Seattle, Washington, United States, July 17-21, 2023. [<a href="My Papers/2023 - ISSTA - CODEP- Grammatical Seq2Seq Model for General-Purpose Code Generation.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=3611202660419197043" target="_blank"> (Cited by 25)</a></span></li>
<li class="paper"><b class="paperinf">[ICSE 2023]</b> <a href="https://lj2lijia.github.io/index.html">Jia Allen Li</a>, Yongmin Li, <b class="myname">Ge Li</b>, Zhi Jin, Xing Hu; SkCoder: A Sketch-based Approach for Automatic Code Generation; Proceedings of the 45th International Conference on Software Engineering (ICSE), Melbourne, Australia, May 14-20, 2023. [<a href="My Papers/2023 - ICSE - SkCoder- A Sketch-based Approach for Automatic Code Generation.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=9006767000376417857" target="_blank"> (Cited by 73)</a></span></li>
<li class="paper"><b class="paperinf">[JSEP, 2023]</b> Huangzhao Zhang, Shuai Lu, Zhi Jin, Lei Ma, Zhuo Li, Yang Liu, <b class="myname">Ge Li</b>; CodeBERT-Attack: Adversarial Attack against Source Code Deep Learning Models via Pre-Trained Model; Journal of Software: Evolution and Process, Vol. 36, No. 3, Apr. 11, 2023. pp 1-29. [<a href="My Papers/2023 - JSEP - CodeBERT-Attack- Adversarial Attack against Source Code Deep Learning Models via Pre-Trained Model.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=17242215769330747796" target="_blank"> (Cited by 12)</a></span></li>
<li class="paper"><b class="paperinf">[ICPC 2023]</b> Kechi Zhang, Zhou Li, Zhi Jin, <b class="myname">Ge Li</b>; Implant Global and Local Hierarchy Information to Sequence based Code Representation Models; Proceedings of the 31st IEEE/ACM International Conference on Program Comprehension (ICPC), Melbourne Australia, May 15-16, 2023. <strong class="distingishpaper">(ACM SIGSOFT Distinguished Paper Award)</strong> [<a href="My Papers/2023 - ICPC - Implant Global and Local Hierarchy Information to Sequence based Code Representation Models.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=16347156324718068718" target="_blank"> (Cited by 10)</a></span></li>
<li class="paper"><b class="paperinf">[SANER 2023]</b> Wenhan Wang, Kechi Zhang, <b class="myname">Ge Li</b>, Shangqing Liu, Anran Li, Zhi Jin, Yang Liu; Learning Program Representations with a Tree-Structured Transformer; Proceedings of the 30th IEEE International Conference on Software Analysis, Evolution and Reengineering (SANER), Macao SAR, China, March 21st-24th, 2023. [<a href="My Papers/2023 - SANER - Learning Program Representations with a Tree-Structured Transformer.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=7669077573597203222,16409416322599397761" target="_blank"> (Cited by 17)</a></span></li>
<li class="paper"><b class="paperinf">[EMNLP 2022]</b> Han Peng, <b class="myname">Ge Li</b>, Yunfei Zhao and Zhi Jin; Rethinking Positional Encoding in Tree Transformer for Code Representation; Proceedings of the 2022 Conference on Empirical Methods in Natural Language Processing(EMNLP 2022), Abu Dhabi, December 7–11, 2022, pp 3204 - 3214. [<a href="My Papers/2022 - EMNLP - Rethinking Positional Encoding in Tree Transformer for Code Representation.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=12668765013189969735" target="_blank"> (Cited by 21)</a></span></li>
<li class="paper"><b class="paperinf">[NeurIPS 2022]</b> Zhang Haojie, <b class="myname">Ge Li</b>, <a href="https://lj2lijia.github.io/index.html">Jia Allen Li</a>, Zhongjin Zhang, Yuqi Zhu, Zhi Jin; Fine-Tuning Pre-Trained Language Models Effectively by Optimizing Subnetworks Adaptively; Proceedings of the 36th Conference on Neural Information Processing Systems (NeurIPS), Online, Nov. 29 - Dec.1, 2022. [<a href="My Papers/2022 - NeurIPS - Fine-Tuning Pre-Trained Language Models Effectively by Optimizing Subnetworks Adaptively.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=204679375623303358" target="_blank"> (Cited by 39)</a></span></li>
<li class="paper"><b class="paperinf">[FSE 2022]</b> Sijie Shen, Xiang Zhu, Yihong Dong, Qizhi Guo, Yankun Zhen, <b class="myname">Ge Li</b>; Incorporating Domain Knowledge through Task Augmentation for Front-End JavaScript Code Generation; Proceedings of The ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE), Singapore, 14th - 16th November 2022. [<a href="My Papers/2022 - FSE - Incorporating Domain Knowledge through Task Augmentation for Front-End JavaScript Code Generation.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=2935214661483064519" target="_blank"> (Cited by 32)</a></span></li>
<li class="paper"><b class="paperinf">[FSE 2022]</b> Lin Shi, Fangwen Mu, Xiao Chen, Song Wang, Junjie Wang, Ye Yang, <b class="myname">Ge Li</b>, Xin Xia, Qing Wang; We Building on the Rock? On the Importance of Data Preprocessing for Code Summarization; Proceedings of The ACM Joint European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESEC/FSE), Singapore, 14th - 16th November 2022. [<a href="My Papers/2022 - FSE - We Building on the Rock - On the Importance of Data Preprocessing for Code Summarization.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=11425270772274155685" target="_blank"> (Cited by 52)</a></span></li>
<li class="paper"><b class="paperinf">[CIKM 2022]</b> Jia Li, Yuyuan Zhao, Zhi Jin, <b class="myname">Ge Li</b>, Tao Shen, Zhengwei Tao, Chongyang Tao; SK2: Integrating Implicit Sentiment Knowledge and Explicit Syntax Knowledge for Aspect-Based Sentiment Analysis; Proceedings of 31st ACM International Conference on Information and Knowledge Management, Atlanta, Georgia, USA, Oct. 17-21, 2022. [<a href="My Papers/2022 - CIKM - SK2- Integrating Implicit Sentiment Knowledge and Explicit Syntax Knowledge for Aspect-Based Sentiment Analysis.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=9603536366096444100" target="_blank"> (Cited by 17)</a></span></li>
<li class="paper"><b class="paperinf">[TOSEM, 2022]</b> Hao Yu, Xing Hu, <b class="myname">Ge Li</b>, Ying Li, Qianxiang Wang, Tao Xie; Assessing and Improving an Evaluation Dataset for Detecting Semantic Code Clones via Deep Learning; ACM Transactions on Software Engineering and Methodology (TOSEM), Vol. 31, No. 4, Article 62, July, 2022, pp 1–25. [<a href="My Papers/2022 - TOSEM - Assessing and Improving an Evaluation Dataset for Detecting Semantic Code Clones via Deep Learning.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=7119519758770072255" target="_blank"> (Cited by 9)</a></span></li>
<li class="paper"><b class="paperinf">[ICSE 2022]</b> Fang Liu, <b class="myname">Ge Li</b>, Zhiyi Fu, Shuai Lu, Yiyang Hao, Zhi Jin; Learning to Recommend Method Names with Global Context; Proceedings of the 44th International Conference on Software Engineering (ICSE 2022), Pittsburgh, PA, USA, May 21-29, 2022. [<a href="My Papers/2022 - ICSE - Learning to Recommend Method Names with Global Context.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=8331415753093554061" target="_blank"> (Cited by 32)</a></span></li>
<li class="paper"><b class="paperinf">[ICSE 2022]</b> Hao Yu, Yiling Lou, Ke Sun, Dezhi Ran, Tao Xie, Dan Hao, Ying Li, <b class="myname">Ge Li</b>, Qianxiang Wang; Automated Assertion Generation via Information Retrieval and Its Integration with Deep Learning; Proceedings of the 44th International Conference on Software Engineering (ICSE 2022), Pittsburgh, PA, USA, May 21-29, 2022. [<a href="My Papers/2022 - ICSE - Automated Assertion Generation via Information Retrieval and Its Integration with Deep Learning.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=10565253083280642909" target="_blank"> (Cited by 53)</a></span></li>
<li class="paper"><b class="paperinf">[ICPC 2022]</b> Kechi Zhang, Wenhan Wang, Huangzhao Zhang, <b class="myname">Ge Li</b>, Zhi Jin; Learning to Represent Programs with Heterogeneous Graphs; Proceedings of the 30th ACM/IEEE International Conference on Program Comprehension (ICPC), Pittsburgh, PA, USA, May 16-17, 2022. [<a href="My Papers/2022 - ICPC - Learning to Represent Programs with Heterogeneous Graphs.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=9461797623113879358" target="_blank"> (Cited by 75)</a></span></li>
<li class="paper"><b class="paperinf">[EMSE, 2022]</b> Fang Liu, <b class="myname">Ge Li</b>, Bolin Wei, Xin Xia, Zhiyi Fu, Zhi Jin; A Unified Multi-task Learning Model for AST-level and Token-level Code Completion; Empirical Software Engineering(EMSE), Vol. 27, Iss. 4, Apr. 18, 2022, pp. 1-38. [<a href="My Papers/2022 - ESE - A Unified Multi-task Learning Model for AST-level and Token-level Code Completion.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=11846517911104568572" target="_blank"> (Cited by 32)</a></span></li>
<li class="paper"><b class="paperinf">[TOSEM, 2022]</b> Huangzhao Zhang, Zhiyi Fu, <b class="myname">Ge Li</b>, Lei Ma, Zhehao Zhao, Hua’an Yang, Yizhe Sun, Yang Liu, Zhi Jin; Towards Robustness of Deep Program Processing Models—Detection, Estimation, and Enhancement; ACM Transactions on Software Engineering and Methodology (TOSEM), Vol. 31, Iss. 3, Apr. 9, 2022, pp. 1-40. [<a href="My Papers/2022 - TOSEM - Towards Robustness of Deep Program Processing Models—Detection, Estimation, and Enhancement.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=8457527175958490683" target="_blank"> (Cited by 52)</a></span></li>
<li class="paper"><b class="paperinf">[TSE, 2022]</b> Hui Liu, Mingzhu Shen, Jiaqi Zhu, Nan Niu , <b class="myname">Ge Li</b>, Lu Zhang; Deep Learning Based Program Generation From Requirements Text: Are We There Yet?; IEEE Transactions on Software Engineering (TSE), Vol. 48, Iss. 4, Apr. 1, 2022. [<a href="My Papers/2022 - TSE - Deep Learning Based Program Generation From Requirements Text- Are We There Yet.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=15942882124174282295" target="_blank"> (Cited by 59)</a></span></li>
<li class="paper"><b class="paperinf">[JSS, 2022]</b> Zhehao Zhao, Bo Yang, <b class="myname">Ge Li</b>, Huai Liu, Zhi Jin; Precise Learning of Source Code Contextual Semantics via Hierarchical Dependence Structure and Graph Attention Networks; Journal of Systems and Software, Volume 184, February 2022. [<a href="My Papers/2022 - JSS - Precise Learning of Source Code Contextual Semantics via Hierarchical Dependence Structure and Graph Attention Networks.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=4712801956783769417" target="_blank"> (Cited by 28)</a></span></li>
<li class="paper"><b class="paperinf">[NeurIPS 2021]</b> Shuai Lu, Daya Guo, Shuo Ren, Junjie Huang, Alexey Svyatkovskiy, Ambrosio Blanco, Colin Clement, Dawn Drain, Daxin Jiang, Duyu Tang, <b class="myname">Ge Li</b>, Lidong Zhou, Linjun Shou, Long Zhou, Michele Tufano, Ming Gong, Ming Zhou, Nan Duan, Neel Sundaresan, Shao Kun Deng, Shengyu Fu, Shujie Liu; Codexglue: A Machine Learning Benchmark Dataset for Code Understanding and Generation; Proceedings of the 35th Conference on Neural Information Processing Systems (NeurIPS), Online, December 6-14, 2021. [<a href="My Papers/2021 - NeurIPS - CodeXGLUE - A Machine Learning Benchmark Dataset for Code Understanding and Generation.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=3348257757676709546" target="_blank"> (Cited by 1022)</a></span></li>
<li class="paper"><b class="paperinf">[NeurIPS 2021]</b> Han Peng, <b class="myname">Ge Li</b>, Wenhan Wang, Yunfei Zhao, Zhi Jin; Integrating Tree Path in Transformer for Code Representation; Proceedings of the 35th Conference on Neural Information Processing Systems (NeurIPS), Online, December 6-14, 2021. [<a href="My Papers/2021 - NeurIPS - Integrating Tree Path in Transformer for Code Representation.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=12295099562232904052" target="_blank"> (Cited by 59)</a></span></li>
<li class="paper"><b class="paperinf">[ASE 2021]</b> <a href="https://lj2lijia.github.io/index.html">Jia Allen Li</a>, Yongmin Li, <b class="myname">Ge Li</b>, Xing Hu, Xin Xia, Zhi Jin; EDITSUM: A Retrieve-and-Edit Framework for Source Code Summarization; Proceedings of the 36th IEEE/ACM International Conference on Automated Software Engineering (ASE), Melbourne, Australia, Sun 14 - Sat 20 November, 2021. [<a href="My Papers/2021 - ASE - EDITSUM- A Retrieve-and-Edit Framework for Source Code Summarization.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=8325896291214985583" target="_blank"> (Cited by 75)</a></span></li>
<li class="paper"><b class="paperinf">[IJCAI 2020]</b> Wenjie Zhang, Zeyu Sun, Qihao Zhu, <b class="myname">Ge Li</b>, Shaowei Cai, Yingfei Xiong, Lu Zhang; NLocalSAT: Boosting Local Search with Solution Prediction; Proceedings of the 29th International Joint Conference on Artificial Intelligence (IJCAI), Yokohama, Japan, January 7-15, 2021, pp. 1177-1183. [<a href="My Papers/2020 - IJCAI - NLocalSAT- Boosting Local Search with Solution Prediction.pdf" target="_blank">PDF</a>] </li>
<li class="paper"><b class="paperinf">[ASE 2020]</b> Fang Liu, <b class="myname">Ge Li</b>, Yunfei Zhao, Zhi Jin; Multi-task Learning based Pre-trained Language Model for Code Completion; Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering (ASE), Melbourne, Australia, Sep. 21-25, 2020. [<a href="My Papers/2020 - ASE - Multi-task Learning based Pre-trained Language Model for Code Completion.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=14779311098625894145" target="_blank"> (Cited by 240)</a></span></li>
<li class="paper"><b class="paperinf">[ASE 2020]</b> Bolin Wei, Yongmin Li, <b class="myname">Ge Li</b>, Xin Xia, Zhi Jin; Retrieve and Refine: Exemplar-based Neural Comment Generation; Proceedings of the 35th IEEE/ACM International Conference on Automated Software Engineering (ASE), Melbourne, Australia, Sep. 21-25, 2020. [<a href="My Papers/2020 - ASE - Retrieve and Refine- Exemplar-based Neural Comment Generation.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=10050087712743088078" target="_blank"> (Cited by 143)</a></span></li>
<li class="paper"><b class="paperinf">[TOSEM, 2020]</b> Wenhan Wang, <b class="myname">Ge Li</b>, Sijie Shen, Xin Xia, Zhi Jin; Modular Tree Network for Source Code Representation Learning; ACM Transactions on Software Engineering and Methodology (TOSEM), Vol. 29, No. 4, Article 31, September 2020. [<a href="My Papers/2020 - TOSEM - Modular Tree Network for Source Code Representation Learning.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=14746368152281960010" target="_blank"> (Cited by 58)</a></span></li>
<li class="paper"><b class="paperinf">[ICPC 2020]</b> Fang Liu, <b class="myname">Ge Li</b>, Xin Xia, Bolin Wei, Zhi Jin; A Self-Attentional Neural Architecture for Code Completion with Multi-Task Learning; Proceedings of the 28th IEEE/ACM International Conference on Program Comprehension (ICPC), Seoul, South Korea, May 23-24, 2020, Pages 37–47. <strong class="distingishpaper">(ACM SIGSOFT Distinguished Paper Award)</strong> [<a href="My Papers/2020 - ICPC - A Self-Attentional Neural Architecture for Code Completion with Multi-Task Learning.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=6413177386307839692" target="_blank"> (Cited by 92)</a></span></li>
<li class="paper"><b class="paperinf">[SANER 2020]</b> Wenhan Wang, <b class="myname">Ge Li</b>, Bo Ma, Xin Xia, Zhi Jin; Detecting Code Clones with Graph Neural Network and Flow-Augmented Abstract Syntax Tree; Proceedings of the 27th IEEE International Conference on Software Analysis (SANER), Evolution and Reengineering London, Ontario, Canada, February 18-21, 2020. [<a href="My Papers/2020 - SANER - Detecting Code Clones with Graph Neural Network and Flow-Augmented Abstract Syntax Tree.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=13251756890009440165" target="_blank"> (Cited by 332)</a></span></li>
<li class="paper"><b class="paperinf">[AAAI 2020]</b> Huangzhao Zhang, Zhuo Li, <b class="myname">Ge Li</b>, Lei Ma, Yang Liu, Zhi Jin; Generating Adversarial Examples for Holding Robustness of Source Code Processing Models; Proceedings of the 34th AAAI Conference on Artificial Intelligence (AAAI), New York, USA, Feb 7-12, 2020. [<a href="My Papers/2020 - AAAI - Generating Adversarial Examples for Holding Robustness of Source Code Processing Models.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=13178546501340244560" target="_blank"> (Cited by 135)</a></span></li>
<li class="paper"><b class="paperinf">[NeurIPS 2019]</b> Bolin Wei, <b class="myname">Ge Li</b>, Xin Xia, Zhiyi Fu, Zhi Jin; Code Generation as a Dual Task of Code Summarization; Proceedings of the 33rd Conference on Neural Information Processing Systems (NeurIPS), Vancouver, Canada, Dec 8-14, 2019, pp.6563-6573. [<a href="My Papers/2019 - NeurIPS - Code Generation as a Dual Task of Code Summarization.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=14746121163037489756" target="_blank"> (Cited by 265)</a></span></li>
<li class="paper"><b class="paperinf">[ICASSP 2019]</b> Bolin Wei, Shuai Lu, Lili Mou, Hao Zhou, Pascal Poupart, <b class="myname">Ge Li</b>, Zhi Jin; Why Do Neural Dialog Systems Generate Short and Meaningless Replies? a Comparison between Dialog and Translation; Proceedings of 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), Brighton, UK, May 12-17, 2019, pp.7290-7294. [<a href="My Papers/2019 - ICASSP - Why Do Neural Dialog Systems Generate Short and Meaningless Replies - a Comparison between Dialog and Translation.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=13515532830315971365" target="_blank"> (Cited by 37)</a></span></li>
<li class="paper"><b class="paperinf">[COMPSAC 2019]</b> Xing Hu, Rui Men, <b class="myname">Ge Li</b>, Zhi Jin; Deep-AutoCoder: Learning to Complete Code Precisely with Induced Code Tokens; Proceedings of 2019 IEEE 43rd Annual Computer Software and Applications Conference (COMPSAC), Milwaukee, Wisconsin, USA, Jul. 15-19, 2019. [<a href="My Papers/2019 - COMPSAC - Deep-AutoCoder- Learning to Complete Code Precisely with Induced Code Tokens.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=7058800976321580272" target="_blank"> (Cited by 10)</a></span></li>
<li class="paper"><b class="paperinf">[EMSE, 2019]</b> Xing Hu, <b class="myname">Ge Li</b>, Xin Xia, David Lo, Zhi Jin; Deep Code Comment Generation with Hybrid Lexical and Syntactical Information; Empirical Software Engineering (EMSE), Vol. 25, Iss. 3, Jun. 18, 2019. pp 2179–2217. [<a href="My Papers/2019 - EMSE - Deep Code Comment Generation with Hybrid Lexical and Syntactical Information.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=2492793035371583114" target="_blank"> (Cited by 302)</a></span></li>
<li class="paper"><b class="paperinf">[ICPC 2019]</b> Hao Yu, Wing Lam, Long Chen, <b class="myname">Ge Li</b>, Tao Xie, Qianxiang Wang; Neural Detection of Semantic Code Clones via Tree-based Convolution; Proceedings of the 27th International Conference on Program Comprehension (ICPC), Montreal, QC, Canada, May 25-31, 2019, pp. 70-80. [<a href="My Papers/2019 - ICPC - Neural Detection of Semantic Code Clones via Tree-based Convolution.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=2966840824411376844" target="_blank"> (Cited by 170)</a></span></li>
<li class="paper"><b class="paperinf">[AAAI 2019]</b> Zeyu Sun, Qihao Zhu, Lili Mou, Yingfei Xiong, <b class="myname">Ge Li</b>, Lu Zhang; A Grammar-Based Structural CNN Decoder for Code Generation; Proceedings of the 33rd AAAI Conference on Artificial Intelligence (AAAI), Honolulu, Hawaii, USA, Jan. 27 – Feb. 1, 2019. [<a href="My Papers/2019 - AAAI - A Grammar-Based Structural CNN Decoder for Code Generation.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=9578481842072162675" target="_blank"> (Cited by 154)</a></span></li>
<li class="paper"><b class="paperinf">[ICPC 2018]</b> Xiaochen Li, He Jiang, Dong Liu, Zhilei Ren, <b class="myname">Ge Li</b>; Unsupervised Deep Bug Report Summarization; Proceedings of the 26th Conference on Program Comprehension (ICPC), 2018. pp. 144-155. [<a href="My Papers/2018 - ICPC - Unsupervised Deep Bug Report Summarization.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=7312637005631604513" target="_blank"> (Cited by 78)</a></span></li>
<li class="paper"><b class="paperinf">[IJCAI 2018]</b> Xing Hu, <b class="myname">Ge Li</b>, Xin Xia, David Lo, Shuai Lu, Zhi Jin; Summarizing Source Code with Transferred API Knowledge; Proceedings of the 27th International Joint Conference on Artificial Intelligence (IJCAI), July 13-19, 2018, Stockholm, Sweden. pp. 2269-2275. [<a href="My Papers/2018 - IJCAI - Summarizing Source Code with Transferred API Knowledge.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=7957314078581455853" target="_blank"> (Cited by 352)</a></span></li>
<li class="paper"><b class="paperinf">[ICPC 2018]</b> Xing Hu, <b class="myname">Ge Li</b>, Xia Xin, David Lo, Zhi Jin; Deep Code Comment Generation; Proceedings of IEEE/ACM 26th International Conference on Program Comprehension (ICPC), Gothenburg, Sweden, 27-28 May 2018, pp.200-210. <strong class="distingishpaper">(ACM SIGSOFT Distinguished Paper Award)</strong> [<a href="My Papers/2018 - ICPC - Deep Code Comment Generation.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=1082840393834763657,13435199831435513765" target="_blank"> (Cited by 884)</a></span></li>
<li class="paper"><b class="paperinf">[KSEM 2017]</b> Yunchuan Chen, Ge Li and Zhi Jin; Learning Sparse Overcomplete Word Vectors without Intermediate Dense Representations; Proceedings of the 10th International Conference on Knowledge Science, Engineering and Management (KSEM), Melbourne, Australia, August,19-20, 2017. [<a href="My Papers/2017 - KSEM - Learning Sparse Overcomplete Word Vectors without Intermediate Dense Representations.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=11064361183778319568" target="_blank"> (Cited by 5)</a></span></li>
<li class="paper"><b class="paperinf">[KSEM 2017]</b> Yangyang Lu, <b class="myname">Ge Li</b>, Zelong hao, Lingfeng Wen and Zhi Jin; Learning To Infer API Mappings From API Documents; Proceedings of the 10th International Conference on Knowledge Science, Engineering and Management (KSEM), Melbourne, Australia, August,19-20, 2017. [<a href="My Papers/2017 - KSEM - Learning To Infer API Mappings From API Documents.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=2075918345690134603" target="_blank"> (Cited by 15)</a></span></li>
<li class="paper"><b class="paperinf">[KSEM 2017]</b> Wenhao Huang, Ge Li and Zhi Jin; Improved Knowledge Base Completion by the Path-Augmented TransR Model; Proceedings of the 10th International Conference on Knowledge Science, Engineering and Management (KSEM), Melbourne, Australia, August,19-20, 2017. [<a href="My Papers/2017 - KSEM - Improved Knowledge Base Completion by the Path-Augmented TransR Model.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=1779453996046869830" target="_blank"> (Cited by 17)</a></span></li>
<li class="paper"><b class="paperinf">[COLING 2016]</b> Lili Mou, Yiping Song, Rui Yan, <b class="myname">Ge Li</b>, Lu Zhang, Zhi Jin; Sequence to Backward and Forward Sequences: A Content-Introducing Approach to Generative Short-Text Conversation; Proceedings of the 26th International Conference on Computational Linguistics (COLING), Osaka, Japan, December 11-17, 2016, pp. 3349–3358. [<a href="My Papers/2016 - COLING - Sequence to Backward and Forward Sequences- A Content-Introducing Approach to Generative Short-Text Conversation.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=15322306336642377359" target="_blank"> (Cited by 300)</a></span></li>
<li class="paper"><b class="paperinf">[COLING 2016]</b> Yan Xu, Ran Jia, Lili Mou, <b class="myname">Ge Li</b>, Yunchuan Chen, Yangyang Lu and Zhi Jin; Improved Relation Classification by Deep Recurrent Neural Networks with Data Augmentation; Proceedings of the 26th International Conference on Computational Linguistics (COLING), Osaka, Japan, December 11-17, 2016, pp. 1461–1470. [<a href="My Papers/2016 - COLING - Improved Relation Classification by Deep Recurrent Neural Networks with Data Augmentation.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=16373480206076190875" target="_blank"> (Cited by 296)</a></span></li>
<li class="paper"><b class="paperinf">[EMNLP 2016]</b> Lili Mou, Zhao Meng, Rui Yan, <b class="myname">Ge Li</b>, Yan Xu, Lu Zhang, Zhi Jin; How Transferable are Neural Networks in NLP Applications?; Proceedings of the 2016 Conference on Empirical Methods in Natural Language Processing (EMNLP), Austin, Texas, November 1-5, 2016, pp. 479–489. [<a href="My Papers/2016 - EMNLP - How Transferable are Neural Networks in NLP Applications.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=7253778827649119205" target="_blank"> (Cited by 3)</a></span></li>
<li class="paper"><b class="paperinf">[ACL 2016]</b> Yunchuan Chen, Lili Mou, Yan Xu, <b class="myname">Ge Li</b>, Zhi Jin; Compressing Neural Language Models by Sparse Word Representations; Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL), Berlin, Germany, August 7-12, 2016, pp. 226–235. [<a href="My Papers/2016 - ACL - Compressing Neural Language Models by Sparse Word Representations.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=782394326508452578" target="_blank"> (Cited by 35)</a></span></li>
<li class="paper"><b class="paperinf">[ACL 2016]</b> Lili Mou, Rui Men, <b class="myname">Ge Li</b>, Yan Xu, Lu Zhang, Rui Yan, Zhi Jin; Natural Language Inference by Tree-Based Convolution and Heuristic Matching; Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (ACL), Berlin, Germany, August 7-12, 2016, pp. 130–136. [<a href="My Papers/2016 - ACL - Natural Language Inference by Tree-Based Convolution and Heuristic Matching.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=125294644878662580" target="_blank"> (Cited by 426)</a></span></li>
<li class="paper"><b class="paperinf">[AAAI 2016]</b> Lili Mou, <b class="myname">Ge Li</b>, Lu Zhang, Tao Wang, Zhi Jin; Convolutional Neural Networks over Tree Structures for Programming Language Processing; Proceedings of 2016 AAAI Conference on Artificial Intelligence, pages 1287-1293, Phoenix, USA, January 12-18, 2016. [<a href="My Papers/2016 - AAAI - Convolutional Neural Networks over Tree Structures for Programming Language Processing.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=12324937124370515795,13202263128577537146,12241704685775538714" target="_blank"> (Cited by 1083)</a></span></li>
<li class="paper"><b class="paperinf">[CIKM 2016]</b> Lili Mou, Ran Jia, Yan Xu, <b class="myname">Ge Li</b>, Lu Zhang, Zhi Jin; Distilling Word Embeddings: An Encoding Approach; Proceedings of the 25th ACM International Conference on Information and Knowledge Management, Indianapolis, USA, October 24-28, 2016. [<a href="My Papers/2016 - CIKM - Distilling Word Embeddings- An Encoding Approach.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=1965175051734755839" target="_blank"> (Cited by 29)</a></span></li>
<li class="paper"><b class="paperinf">[KSEM 2016]</b> Zhao Meng, Lili Mou, Ge Li and Zhi Jin; Context-Aware Tree-Based Convolutional Neural Networks for Natural Language Inference; Proceedings of 9th International Conference on Knowledge Science, Engineering and Management, Passau, Germany, October 4-8, 2016, LNAI 9983, pp. 515–526. [<a href="My Papers/2016 - KSEM - Context-Aware Tree-Based Convolutional Neural Networks for Natural Language Inference.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=6133281504533346090" target="_blank"> (Cited by 1)</a></span></li>
<li class="paper"><b class="paperinf">[KSEM 2016]</b> Yangyang Lu, <b class="myname">Ge Li</b>, Rui Miao, Zhi Jin; Learning Embeddings Of API Tokens To Facilitate Deep Learning Based Program Processing; Proceedings of 9th International Conference on Knowledge Science, Engineering and Management, Passau, Germany, October 4-8, 2016, LNAI 9983, pp. 527–539. [<a href="My Papers/2016 - KSEM - Learning Embeddings Of API Tokens To Facilitate Deep Learning Based Program Processing.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=11569005228340381864" target="_blank"> (Cited by 4)</a></span></li>
<li class="paper"><b class="paperinf">[EMNLP 2015]</b> Hao Peng, Lili Mou, <b class="myname">Ge Li</b>, Yan Xu, Lu Zhang, Zhi Jin; A Comparative Study on Regularization Strategies for Embedding-based Neural Networks; Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, Lisboa, Portugal, September 17–21, 2015. [<a href="My Papers/2015 - EMNLP - A Comparative Study on Regularization Strategies for Embedding-based Neural Networks.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=8996515888398655023" target="_blank"> (Cited by 40)</a></span></li>
<li class="paper"><b class="paperinf">[KSEM 2015]</b> Hao Peng, Lili Mou, <b class="myname">Ge Li</b>, Yuxuan Liu, Lu Zhang and Zhi Jin; Building Program Vector Representations for Deep Learning; Proceedings of the 8th International Conference on Knowledge Science, Engineering and Management, Chongqing, China October 28-30, 2015. pp. 547-553. [<a href="My Papers/2015 - KSEM - Building Program Vector Representations for Deep Learning.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=17453886396576210217,11334042996923277451" target="_blank"> (Cited by 225)</a></span></li>
<li class="paper"><b class="paperinf">[EMNLP 2015]</b> Lili Mou, Hao Peng, <b class="myname">Ge Li</b>, Yan Xu, Lu Zhang, Zhi Jin; Discriminative Neural Sentence Modeling by Tree-Based Convolution; Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, Lisbon, Portugal, 17-21 September, 2015. pp. 2315–2325. [<a href="My Papers/2015 - EMNLP - Discriminative Neural Sentence Modeling by Tree-Based Convolution.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=11792353655532335112" target="_blank"> (Cited by 159)</a></span></li>
<li class="paper"><b class="paperinf">[EMNLP 2015]</b> Yan Xu, Lili Mou, <b class="myname">Ge Li</b>, Lu Zhang, Zhi Jin; Classifying Relations via Long Short Term Memory Networks along Shortest Dependency Paths; Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing, Lisboa, Portugal, September 17–21, 2015. [<a href="My Papers/2015 - EMNLP - Classifying Relations via Long Short Term Memory Networks along Shortest Dependency Paths.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=7434923510943166052,10712477119633134480" target="_blank"> (Cited by 881)</a></span></li>
<li class="paper"><b class="paperinf">[KSEM 2014]</b> Lili Mou, <b class="myname">Ge Li</b>, Zhi Jin, Lu Zhang; Verification based on Hyponymy Hierarchical Characteristics for Web-based Hyponymy Discovery; Proceedings of the International Conference on Knowledge Science, Engineering and Management 2014, Lecture Notes in Computer Science Volume 8793, 2014, pp 81-92. [<a href="My Papers/2014 - KSEM - Verification based on Hyponymy Hierarchical Characteristics for Web-based Hyponymy Discovery.pdf" target="_blank">PDF</a>] </li>
<li class="paper"><b class="paperinf">[IJSEKE, 2014]</b> Yan Xu, <b class="myname">Ge Li</b>, Lili Mou, Yangyang Lu; Learning Non-taxonomy Relations on Demand for Ontology Extension; Proceedings of the International Journal of Software Engineering and Knowledge Engineering, October 2014, Vol.24, No.08, pp.1159-1175. [<a href="My Papers/2014 - IJSEKE - Learning Non-Taxonomic Relations on Demand for Ontology Extension.pdf" target="_blank">PDF</a>]<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=8163187585123069639" target="_blank"> (Cited by 11)</a></span></li> </ul> <h2>Basic Papers on Deep Learning based Code Processing</h2> <ul class="paperlist">
<li class="paper"><b class="paperinf">[arXiv 2015]</b> Lili Mou, Rui Men, <b class="myname">Ge Li</b>, Lu Zhang, Zhi Jin; On End-to-End Program Generation from User Intention by Deep Neural Networks; arXiv preprint, <a href="https://arxiv.org/abs/1510.07211" target="_blank">arXiv: 1510.07211</a>, 2015.<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=5712048843366927900" target="_blank"> (Cited by 80)</a></span></li>
<li class="paper"><b class="paperinf">[arXiv 2014]</b> Lili Mou, <b class="myname">Ge Li</b>, Zhi Jin, Lu Zhang, Tao Wang; TBCNN: A Tree-Based Convolutional Neural Network for Programming Language Processing; arXiv preprint, <a href="https://arxiv.org/abs/1409.5718" target="_blank">arXiv: 1409.5718</a>, 2014.</li>
<li class="paper"><b class="paperinf">[arXiv 2014]</b> Lili Mou, <b class="myname">Ge Li</b>, Yuxuan Liu, Hao Peng, Zhi Jin, Yan Xu, Lu Zhang; Building Program Vector Representations for Deep Learning; arXiv preprint, <a href="https://arxiv.org/abs/1409.3358" target="_blank">arXiv: 1409.3358</a>, 2014.<span class="citation-count" style="color: green; font-size: 0.8em;"><a href="https://scholar.google.com/scholar?oi=bibs&amp;hl=en&amp;cites=17453886396576210217,11334042996923277451" target="_blank"> (Cited by 225)</a></span></li>
</ul>
</div>
</div>
<br/>
<br/>
<div class="bottomenu"> </div>
</body>
</html>
